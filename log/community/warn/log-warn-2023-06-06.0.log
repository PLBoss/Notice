2023-06-06 12:36:54,420 WARN [http-nio-8080-exec-4] o.s.w.s.m.m.a.ExceptionHandlerExceptionResolver [AbstractHandlerExceptionResolver.java:198] Resolved [org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis; nested exception is io.lettuce.core.RedisConnectionException: Unable to connect to localhost:6379]
2023-06-06 12:37:58,644 WARN [http-nio-8080-exec-4] o.s.w.s.m.m.a.ExceptionHandlerExceptionResolver [AbstractHandlerExceptionResolver.java:198] Resolved [org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis; nested exception is io.lettuce.core.RedisConnectionException: Unable to connect to localhost:6379]
2023-06-06 12:42:56,888 WARN [restartedMain] o.a.c.c.C.[.[.[/community] [DirectJDKLog.java:173] Cannot deserialize session attribute [SPRING_SECURITY_CONTEXT] for session [D2D062AB8AECC9CEBB663FC63EB30136]
2023-06-06 12:50:49,938 WARN [http-nio-8080-exec-9] c.z.h.p.PoolBase [PoolBase.java:176] HikariPool-1 - Failed to validate connection com.mysql.cj.jdbc.ConnectionImpl@62c4394c (No operations allowed after connection closed.). Possibly consider using a shorter maxLifetime value.
2023-06-06 12:50:49,940 WARN [http-nio-8080-exec-9] c.z.h.p.PoolBase [PoolBase.java:176] HikariPool-1 - Failed to validate connection com.mysql.cj.jdbc.ConnectionImpl@20b99b2b (No operations allowed after connection closed.). Possibly consider using a shorter maxLifetime value.
2023-06-06 12:50:49,941 WARN [http-nio-8080-exec-9] c.z.h.p.PoolBase [PoolBase.java:176] HikariPool-1 - Failed to validate connection com.mysql.cj.jdbc.ConnectionImpl@6374d829 (No operations allowed after connection closed.). Possibly consider using a shorter maxLifetime value.
2023-06-06 12:50:49,943 WARN [http-nio-8080-exec-9] c.z.h.p.PoolBase [PoolBase.java:176] HikariPool-1 - Failed to validate connection com.mysql.cj.jdbc.ConnectionImpl@5d501ac5 (No operations allowed after connection closed.). Possibly consider using a shorter maxLifetime value.
2023-06-06 12:50:49,945 WARN [http-nio-8080-exec-9] c.z.h.p.PoolBase [PoolBase.java:176] HikariPool-1 - Failed to validate connection com.mysql.cj.jdbc.ConnectionImpl@73f1d2f8 (No operations allowed after connection closed.). Possibly consider using a shorter maxLifetime value.
2023-06-06 12:54:55,621 WARN [http-nio-8080-exec-4] c.z.h.p.PoolBase [PoolBase.java:176] HikariPool-1 - Failed to validate connection com.mysql.cj.jdbc.ConnectionImpl@7a6878c0 (No operations allowed after connection closed.). Possibly consider using a shorter maxLifetime value.
2023-06-06 12:54:55,624 WARN [http-nio-8080-exec-4] c.z.h.p.PoolBase [PoolBase.java:176] HikariPool-1 - Failed to validate connection com.mysql.cj.jdbc.ConnectionImpl@5cfbd155 (No operations allowed after connection closed.). Possibly consider using a shorter maxLifetime value.
2023-06-06 12:54:55,626 WARN [http-nio-8080-exec-4] c.z.h.p.PoolBase [PoolBase.java:176] HikariPool-1 - Failed to validate connection com.mysql.cj.jdbc.ConnectionImpl@587b6e12 (No operations allowed after connection closed.). Possibly consider using a shorter maxLifetime value.
2023-06-06 12:54:55,628 WARN [http-nio-8080-exec-4] c.z.h.p.PoolBase [PoolBase.java:176] HikariPool-1 - Failed to validate connection com.mysql.cj.jdbc.ConnectionImpl@616cb3a5 (No operations allowed after connection closed.). Possibly consider using a shorter maxLifetime value.
2023-06-06 12:54:55,630 WARN [http-nio-8080-exec-4] c.z.h.p.PoolBase [PoolBase.java:176] HikariPool-1 - Failed to validate connection com.mysql.cj.jdbc.ConnectionImpl@6a222ff3 (No operations allowed after connection closed.). Possibly consider using a shorter maxLifetime value.
2023-06-06 12:57:33,060 WARN [restartedMain] o.a.c.c.C.[.[.[/community] [DirectJDKLog.java:173] Cannot deserialize session attribute [SPRING_SECURITY_CONTEXT] for session [D2D062AB8AECC9CEBB663FC63EB30136]
2023-06-06 13:01:38,962 WARN [restartedMain] o.a.c.c.C.[.[.[/community] [DirectJDKLog.java:173] Cannot deserialize session attribute [SPRING_SECURITY_CONTEXT] for session [D2D062AB8AECC9CEBB663FC63EB30136]
2023-06-06 13:07:19,264 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:737] [Consumer clientId=consumer-6, groupId=test-consumer-group] Asynchronous auto-commit of offsets {publish-0=OffsetAndMetadata{offset=11, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
2023-06-06 13:07:19,265 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:759] [Consumer clientId=consumer-6, groupId=test-consumer-group] Synchronous auto-commit of offsets {publish-0=OffsetAndMetadata{offset=11, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
2023-06-06 13:07:22,166 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:759] [Consumer clientId=consumer-4, groupId=test-consumer-group] Synchronous auto-commit of offsets {comment-0=OffsetAndMetadata{offset=2, metadata=''}, like-0=OffsetAndMetadata{offset=8, metadata=''}, follow-0=OffsetAndMetadata{offset=1, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
2023-06-06 13:07:24,006 WARN [HikariPool-1 housekeeper] c.z.h.p.HikariPool [HikariPool.java:766] HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=54s769ms912µs600ns).
2023-06-06 13:53:20,603 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:737] [Consumer clientId=consumer-4, groupId=test-consumer-group] Asynchronous auto-commit of offsets {comment-0=OffsetAndMetadata{offset=2, metadata=''}, like-0=OffsetAndMetadata{offset=8, metadata=''}, follow-0=OffsetAndMetadata{offset=1, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
2023-06-06 13:53:20,603 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:759] [Consumer clientId=consumer-4, groupId=test-consumer-group] Synchronous auto-commit of offsets {comment-0=OffsetAndMetadata{offset=2, metadata=''}, like-0=OffsetAndMetadata{offset=8, metadata=''}, follow-0=OffsetAndMetadata{offset=1, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
2023-06-06 13:53:20,604 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:737] [Consumer clientId=consumer-2, groupId=test-consumer-group] Asynchronous auto-commit of offsets {delete-0=OffsetAndMetadata{offset=0, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
2023-06-06 13:53:20,604 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:737] [Consumer clientId=consumer-6, groupId=test-consumer-group] Asynchronous auto-commit of offsets {publish-0=OffsetAndMetadata{offset=11, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
2023-06-06 13:53:20,604 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:759] [Consumer clientId=consumer-6, groupId=test-consumer-group] Synchronous auto-commit of offsets {publish-0=OffsetAndMetadata{offset=11, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
2023-06-06 13:53:20,604 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:759] [Consumer clientId=consumer-2, groupId=test-consumer-group] Synchronous auto-commit of offsets {delete-0=OffsetAndMetadata{offset=0, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
2023-06-06 13:53:23,191 WARN [HikariPool-1 housekeeper] c.z.h.p.HikariPool [HikariPool.java:766] HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=31m28s942ms436µs200ns).
2023-06-06 15:19:00,288 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:737] [Consumer clientId=consumer-4, groupId=test-consumer-group] Asynchronous auto-commit of offsets {comment-0=OffsetAndMetadata{offset=2, metadata=''}, like-0=OffsetAndMetadata{offset=8, metadata=''}, follow-0=OffsetAndMetadata{offset=1, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
2023-06-06 15:19:00,288 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:759] [Consumer clientId=consumer-4, groupId=test-consumer-group] Synchronous auto-commit of offsets {comment-0=OffsetAndMetadata{offset=2, metadata=''}, like-0=OffsetAndMetadata{offset=8, metadata=''}, follow-0=OffsetAndMetadata{offset=1, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
2023-06-06 15:19:00,290 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:737] [Consumer clientId=consumer-6, groupId=test-consumer-group] Asynchronous auto-commit of offsets {publish-0=OffsetAndMetadata{offset=11, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
2023-06-06 15:19:00,290 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:759] [Consumer clientId=consumer-6, groupId=test-consumer-group] Synchronous auto-commit of offsets {publish-0=OffsetAndMetadata{offset=11, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
2023-06-06 15:19:02,910 WARN [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator [ConsumerCoordinator.java:759] [Consumer clientId=consumer-2, groupId=test-consumer-group] Synchronous auto-commit of offsets {delete-0=OffsetAndMetadata{offset=0, metadata=''}} failed: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
2023-06-06 15:19:27,888 WARN [HikariPool-1 housekeeper] c.z.h.p.HikariPool [HikariPool.java:766] HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=49m4s81ms168µs900ns).
